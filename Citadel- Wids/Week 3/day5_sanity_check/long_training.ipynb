{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2e6e53-767b-4c47-b5c2-a98f80444dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add Week 3 to Python path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "from day2_environment.trading_env import TradingEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d101991-26d2-4da0-8b7b-ed4413e6d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/ppo_day5\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = TradingEnv(max_steps=100)\n",
    "env = Monitor(env, log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc480cf-adbc-407c-ad92-d074fd5abdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/ppo_day5\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "new_logger = configure(log_dir, [\"stdout\", \"csv\"])\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.set_logger(new_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598280f4-bd5c-4839-90a5-59b7eb3b5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.419   |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.499      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013274909 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00735     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.00301     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008393648 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.841      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 0.00262     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -0.477     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 394        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01109417 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.00474    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0268    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 0.00181    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 100        |\n",
      "|    ep_rew_mean          | -0.446     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 387        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00984058 |\n",
      "|    clip_fraction        | 0.0724     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | -0.173     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0482    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    value_loss           | 0.00199    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.414       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 380          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134353135 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0568      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0242      |\n",
      "|    value_loss           | 0.000936     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.325      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008540595 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.000535    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.264      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013001124 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.000262    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015821967 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.000119    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013554493 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.000177    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.137      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012239398 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00476     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 5.07e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.115      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008654612 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 5.27e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010858952 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.958      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24e-06    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 2.64e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0807     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011495245 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 3.1e-05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.0685      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066493317 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.873       |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0494      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    value_loss           | 2.33e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0584     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010510225 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 2.01e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0494     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008574739 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00893    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 2e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0431     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006620908 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 1.22e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.0367      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066877687 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.663       |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 1.7e-05      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 100       |\n",
      "|    ep_rew_mean          | -0.0308   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 378       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0061227 |\n",
      "|    clip_fraction        | 0.0427    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.622    |\n",
      "|    explained_variance   | 0.32      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0483   |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.00989  |\n",
      "|    value_loss           | 5.11e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0258     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004654779 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00397    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.0211      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051328847 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0126      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00853     |\n",
      "|    value_loss           | 1.31e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -0.0173      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035247505 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | -0.000733    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 1.01e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0146     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003923644 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | -0.0202     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00328    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    value_loss           | 2.15e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -0.0122     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003523066 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | -0.019      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    value_loss           | 6.21e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x13e15b98050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0dd8a2-f82d-4167-8929-127b158515c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved day5_metrics.csv\n",
      "    time/total_timesteps  rollout/ep_rew_mean  train/entropy_loss\n",
      "0                   2048            -0.419067                 NaN\n",
      "20                 43008            -0.025752           -0.533455\n",
      "    time/total_timesteps  rollout/ep_rew_mean  train/entropy_loss\n",
      "0                   2048            -0.419067                 NaN\n",
      "20                 43008            -0.025752           -0.533455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "progress_path = os.path.join(log_dir, \"progress.csv\")\n",
    "\n",
    "progress = pd.read_csv(\n",
    "    progress_path,\n",
    "    usecols=[\n",
    "        \"time/total_timesteps\",\n",
    "        \"rollout/ep_rew_mean\",\n",
    "        \"train/entropy_loss\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Downsample heavily to avoid memory issues\n",
    "progress_small = progress.iloc[::20]\n",
    "\n",
    "progress_small.to_csv(\"day5_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Saved day5_metrics.csv\")\n",
    "print(progress_small.head())\n",
    "print(progress_small.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a943a0e-de7a-4234-b31e-1370d33e5127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n",
      "Action: 0, Reward: 0.00000, Inventory: 0.00\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "\n",
    "for _ in range(30):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    print(\n",
    "        f\"Action: {action}, \"\n",
    "        f\"Reward: {reward:.5f}, \"\n",
    "        f\"Inventory: {info['inventory']:.2f}\"\n",
    "    )\n",
    "\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e63c50de-c505-418d-ae64-ef1142dc0525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"ppo_trading_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d3b34-933a-4fa6-a6ca-7fe8888d5947",
   "metadata": {},
   "source": [
    "## Day 5 â€“ Learnability Verdict\n",
    "\n",
    "A 50,000-timestep PPO training run was completed successfully using the\n",
    "risk-aware TradingEnv developed in earlier stages.\n",
    "\n",
    "Training metrics were logged using Stable-Baselines3 monitoring utilities.\n",
    "Due to repeated Jupyter kernel crashes during plotting on Windows,\n",
    "metrics were exported and analyzed externally from the generated CSV logs.\n",
    "\n",
    "Observations:\n",
    "- Mean episode reward stabilized near zero over training.\n",
    "- Policy entropy decreased gradually, indicating convergence of the policy.\n",
    "- The learned policy converged to a deterministic and conservative\n",
    "  Hold-dominant strategy with near-zero inventory.\n",
    "\n",
    "Verdict:\n",
    "The agent demonstrates stable and coherent learning behavior.\n",
    "The environment, reward function, and PPO algorithm together form a\n",
    "well-posed and learnable system.\n",
    "\n",
    "One concrete improvement:\n",
    "Introduce structured order flow and multi-agent interactions to create\n",
    "non-zero expected trading opportunities and richer market dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0732d-9819-447d-92cf-8bad8dad1b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
